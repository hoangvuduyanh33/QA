{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DrQA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7wHOytAZ7Eu",
        "outputId": "1782ecf3-286b-400e-957b-f399e1f6c02a"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Apr 28 17:58:23 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TC4lhB--ZRRS",
        "outputId": "67b89a8a-9002-4881-b99d-78b1460e27a5"
      },
      "source": [
        "!git clone https://github.com/facebookresearch/DrQA.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DrQA'...\n",
            "remote: Enumerating objects: 265, done.\u001b[K\n",
            "remote: Total 265 (delta 0), reused 0 (delta 0), pack-reused 265\u001b[K\n",
            "Receiving objects: 100% (265/265), 562.37 KiB | 14.80 MiB/s, done.\n",
            "Resolving deltas: 100% (127/127), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzZRhDfBnT7m",
        "outputId": "e689bef7-7688-4284-c2cc-9d2853b9cfe0"
      },
      "source": [
        "%cd DrQA\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py develop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DrQA\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.22.2.post1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (4.41.1)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (2.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (3.2.5)\n",
            "Collecting elasticsearch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/5c/60a32dfc24da07703b5b32d9935bcc36786a9176e67117c4b6215fd6d914/elasticsearch-7.12.1-py2.py3-none-any.whl (339kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 10.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (1.0.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable->-r requirements.txt (line 6)) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from prettytable->-r requirements.txt (line 6)) (3.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->-r requirements.txt (line 8)) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elasticsearch->-r requirements.txt (line 9)) (2020.12.5)\n",
            "Requirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from elasticsearch->-r requirements.txt (line 9)) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->prettytable->-r requirements.txt (line 6)) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->prettytable->-r requirements.txt (line 6)) (3.4.1)\n",
            "Installing collected packages: elasticsearch\n",
            "Successfully installed elasticsearch-7.12.1\n",
            "running develop\n",
            "running egg_info\n",
            "creating drqa.egg-info\n",
            "writing drqa.egg-info/PKG-INFO\n",
            "writing dependency_links to drqa.egg-info/dependency_links.txt\n",
            "writing requirements to drqa.egg-info/requires.txt\n",
            "writing top-level names to drqa.egg-info/top_level.txt\n",
            "writing manifest file 'drqa.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE' (matched pattern 'LICEN[CS]E*')\n",
            "writing manifest file 'drqa.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.7/dist-packages/drqa.egg-link (link to .)\n",
            "Adding drqa 0.1.0 to easy-install.pth file\n",
            "\n",
            "Installed /content/DrQA\n",
            "Processing dependencies for drqa==0.1.0\n",
            "Searching for elasticsearch==7.12.1\n",
            "Best match: elasticsearch 7.12.1\n",
            "Adding elasticsearch 7.12.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for nltk==3.2.5\n",
            "Best match: nltk 3.2.5\n",
            "Adding nltk 3.2.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for prettytable==2.1.0\n",
            "Best match: prettytable 2.1.0\n",
            "Adding prettytable 2.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tqdm==4.41.1\n",
            "Best match: tqdm 4.41.1\n",
            "Adding tqdm 4.41.1 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for regex==2019.12.20\n",
            "Best match: regex 2019.12.20\n",
            "Adding regex 2019.12.20 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for termcolor==1.1.0\n",
            "Best match: termcolor 1.1.0\n",
            "Adding termcolor 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for scikit-learn==0.22.2.post1\n",
            "Best match: scikit-learn 0.22.2.post1\n",
            "Adding scikit-learn 0.22.2.post1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.19.5\n",
            "Best match: numpy 1.19.5\n",
            "Adding numpy 1.19.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for certifi==2020.12.5\n",
            "Best match: certifi 2020.12.5\n",
            "Adding certifi 2020.12.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for importlib-metadata==3.10.1\n",
            "Best match: importlib-metadata 3.10.1\n",
            "Adding importlib-metadata 3.10.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for wcwidth==0.2.5\n",
            "Best match: wcwidth 0.2.5\n",
            "Adding wcwidth 0.2.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for joblib==1.0.1\n",
            "Best match: joblib 1.0.1\n",
            "Adding joblib 1.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==3.7.4.3\n",
            "Best match: typing-extensions 3.7.4.3\n",
            "Adding typing-extensions 3.7.4.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for zipp==3.4.1\n",
            "Best match: zipp 3.4.1\n",
            "Adding zipp 3.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for drqa==0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sot2KgqYnUYk",
        "outputId": "8b25fa32-5c8e-48dd-b0a9-000d1a0c10db"
      },
      "source": [
        "!./install_corenlp.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Specify download path or enter to use default (data/corenlp): /content/corenlp\n",
            "Will download to: /content/corenlp\n",
            "/tmp /content/DrQA\n",
            "--2021-04-28 17:59:15--  http://nlp.stanford.edu/software/stanford-corenlp-full-2017-06-09.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/software/stanford-corenlp-full-2017-06-09.zip [following]\n",
            "--2021-04-28 17:59:16--  https://nlp.stanford.edu/software/stanford-corenlp-full-2017-06-09.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://downloads.cs.stanford.edu/nlp/software/stanford-corenlp-full-2017-06-09.zip [following]\n",
            "--2021-04-28 17:59:16--  https://downloads.cs.stanford.edu/nlp/software/stanford-corenlp-full-2017-06-09.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 390211140 (372M) [application/zip]\n",
            "Saving to: ‘stanford-corenlp-full-2017-06-09.zip’\n",
            "\n",
            "stanford-corenlp-fu 100%[===================>] 372.13M  5.03MB/s    in 70s     \n",
            "\n",
            "2021-04-28 18:00:26 (5.31 MB/s) - ‘stanford-corenlp-full-2017-06-09.zip’ saved [390211140/390211140]\n",
            "\n",
            "Archive:  stanford-corenlp-full-2017-06-09.zip\n",
            "   creating: stanford-corenlp-full-2017-06-09/\n",
            "  inflating: stanford-corenlp-full-2017-06-09/xom-1.2.10-src.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/CoreNLP-to-HTML.xsl  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/README.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/jollyday-0.4.9-sources.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/LIBRARY-LICENSES  \n",
            "   creating: stanford-corenlp-full-2017-06-09/sutime/\n",
            "  inflating: stanford-corenlp-full-2017-06-09/sutime/defs.sutime.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/sutime/english.sutime.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/sutime/english.holidays.sutime.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/stanford-corenlp-3.8.0-javadoc.jar  \n",
            " extracting: stanford-corenlp-full-2017-06-09/ejml-0.23-src.zip  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/stanford-corenlp-3.8.0-models.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/input.txt.xml  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/build.xml  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/pom.xml  \n",
            "   creating: stanford-corenlp-full-2017-06-09/tokensregex/\n",
            "  inflating: stanford-corenlp-full-2017-06-09/tokensregex/color.input.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/tokensregex/retokenize.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/tokensregex/color.properties  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/tokensregex/color.rules.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/javax.json-api-1.0-sources.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/protobuf.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/StanfordDependenciesManual.pdf  \n",
            "   creating: stanford-corenlp-full-2017-06-09/patterns/\n",
            "  inflating: stanford-corenlp-full-2017-06-09/patterns/example.properties  \n",
            " extracting: stanford-corenlp-full-2017-06-09/patterns/otherpeople.txt  \n",
            " extracting: stanford-corenlp-full-2017-06-09/patterns/goldplaces.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/patterns/stopwords.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/patterns/presidents.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/patterns/names.txt  \n",
            " extracting: stanford-corenlp-full-2017-06-09/patterns/places.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/patterns/goldnames.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/slf4j-simple.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/input.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/joda-time.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/xom.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/StanfordCoreNlpDemo.java  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/slf4j-api.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/ejml-0.23.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/javax.json.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/Makefile  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/corenlp.sh  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/joda-time-2.9-sources.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/stanford-corenlp-3.8.0-sources.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/stanford-corenlp-3.8.0.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/jollyday.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/ShiftReduceDemo.java  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/SemgrexDemo.java  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/LICENSE.txt  \n",
            "/content/DrQA\n",
            "Add to ~/.bashrc CLASSPATH (recommended)? [yes/no]: no\n",
            "\n",
            "*** NOW RUN: ***\n",
            "\n",
            "export CLASSPATH=$CLASSPATH:/content/corenlp/*\n",
            "\n",
            "****************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-jxv7dNbePX"
      },
      "source": [
        "import drqa.tokenizers\n",
        "drqa.tokenizers.set_default('corenlp_classpath', '/content/corenlp/*')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDWjfOeWbpYe",
        "outputId": "b806f3a9-bc6d-4100-f677-a1a4acea552d"
      },
      "source": [
        "from drqa.tokenizers import CoreNLPTokenizer\n",
        "tok = CoreNLPTokenizer()\n",
        "tok.tokenize('hello world').words()  # Should complete immediately"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello', 'world']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWXjf7eKpns1",
        "outputId": "787a6914-cab8-40e0-a875-a5444860181f"
      },
      "source": [
        "!wget -P ./data/reader https://dl.fbaipublicfiles.com/drqa/single.mdl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DrQA\n",
            "--2021-04-28 18:05:27--  https://dl.fbaipublicfiles.com/drqa/single.mdl\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 172.67.9.4, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 138279042 (132M) [binary/octet-stream]\n",
            "Saving to: ‘/content/DrQA/data/reader/single.mdl’\n",
            "\n",
            "single.mdl          100%[===================>] 131.87M  41.3MB/s    in 3.2s    \n",
            "\n",
            "2021-04-28 18:05:30 (41.3 MB/s) - ‘/content/DrQA/data/reader/single.mdl’ saved [138279042/138279042]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOSQNt4QlC6P"
      },
      "source": [
        "!python scripts/reader/interactive.py --tokenizer regexp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJPZiRKhq74v"
      },
      "source": [
        "!wget -P ./data/wikipedia https://dl.fbaipublicfiles.com/drqa/docs-tfidf-ngram%3D2-hash%3D16777216-tokenizer%3Dsimple.npz.gz\n",
        "!gzip -d ./data/wikipedia/docs-tfidf-ngram=2-hash=16777216-tokenizer=simple.npz.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIqffVd7qtYN"
      },
      "source": [
        "!python scripts/pipeline/interactive.py"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}